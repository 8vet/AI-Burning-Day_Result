# 딥롤

인공지능 백엔드를 기반으로 롤 챔피언/아이템 등을 추천해주는 시스템.

### 프로젝트 특징
- 쿠버네티스를 기반으로 안정적인 서비스 CI/CD를 야기하였습니다.
- 유전 알고리즘을 통해 수많은 조합의 해를 효율적으로 탐색하였습니다.
- DNN 학습을 위해 효과적인 데이터 가공을 고려하였습니다. (아이템 조합)
- 크롤러를 queue 기반으로 구성하여 fail-over 하게 구성하였습니다. (중간에 끊겨도 다시 이어작업할 수있음, API Rate Limit에 구애받지않음 등)
- REACT 기반으로 프론트를 효율적으로 구성하였습니다.

### 주소
- http://deeplol.eunchan.com

### 동영상
- 쿠버네티스 롤링업데이트 영상 : https://youtu.be/y2DR6pUQl7A
- 유전알고리즘 시연 영상 : https://youtu.be/zMZbgyFK_ls

### 기능별 코멘트
- *under construction* DNN 기반 챔피언별 아이템 추천 : 챔피언 별로 다음 아이템을 무엇을 갈지 추천해 주려고 하였습니다. 훈련 데이터는 게임의 끝난 상태의 아이템을 보여주기때문에, 해당 아이템의 서브 아이템 즉, 하위 아이템들로 구성하여 napscak 알고리즘을 응용하여 해당 아이템들을 하위아이템으로 replace 하여 학습하려고 하였습니다. 데이터전처리하고 학습하고 하는데 생각보다 효율이 좋지않아 모델링을 계속 고민하다가 시간이 부족하여 완성하지 못하였습니다.
- 유전알고리즘 : 챔피언의 조합은 매우 다양한 경우의 수가 있습니다. (140C5) 이러한 이유로 모든 조합에 대해 통계를 내지 못하기 때문에 유전알고리즘을 사용하여 제한시간 동안 최선의 조합을 추천해주게 됩니다. 시뮬레이션 개념을 도입하여 초기 유전자 셋과 뎁스 수를 직접 설정하여 체험할 수 있게 하였습니다.
- 쿠버네티스 기반으로 마이크로 서비스를 준비하고, 쿠베플로우 느낌으로 이후 데이터 파싱, 가공, 훈련, 및 모델 배포 등을 도커라이즈된 앱으로 작성하여 스케일 가능하게 설계하였습니다. 시간이 부족하여 많은 부분이 채워지지 못하였지만, GA를 Service로 연결하여 Cluster IP DNS 로 연결하는 등 내부 통신을 하나 구현하였습니다.




### 분야별 설명

# (실패) OpenCV Integration 

최초 목적은 사용자가 게임화면을 캡쳐하면 현재 게임의 상황을 인식하고 feature extraction을 통해 딥러닝 백엔드를 활용하려 하였습니다. 

그러기 위해 영상처리가 필수였는데 딥러닝기반 오브젝트 디텍션을 사용하기에는 커스텀한 레이블링 인풋들이 필요했는데 이 데이터셋을 짧은시간 내에 구성하기 쉽지않았습니다. 이에 OpenCV로 Match Template 과 같은 고전적인 영상처리를 사용하였는데, 해상도별 다른부분과 그 이후 후처리 부분에서 한계가 느껴서 약 11시간 투자를 한 뒤에 실패를 기록하고 넘어가게 되었습니다..

# Deep LoL item recommendation (DNN)

본인의 아이템 트리와 본인을 포함한 챔피언 10가지를 뉴럴넷의 입력으로 사용합니다.
현재 나의 아이템 트리 상황과 아군과 적군의 챔피언의 종류에 따라 현 상황에 맞는 아이템을 추천합니다.

## 1. DB 가공

Riot API를 통해 크롤링한 DB에서 필요한 정보들을 추출하였습니다.
match data에서 아이템 정보와 챔피언 정보만을 가져와 이긴 팀에 속한 챔피언을 기준으로 데이터를 가공했습니다.

number of data : 160,000

## 2. Deep Learning

### input

* 10 Champion IDs
* 6 Item IDs

### output

* 1 Item

---

##딥러닝 학습을 위한 

### input

* 게임 종료 후 이긴 유저의 데이터를 사용.
* 완성된 6가지의 아이템 트리중 하나씩 제거하며 데이터 가공.
* embedding을 통해 데이터 압축.

### target

* 제거한 아이템을 학습할 때 target으로 이용.

## 3. 결과

결론적으로, 성능이 좋지 않았습니다.
LoL에서 146가지의 챔피언, 243가지의 아이템의 밸런스를 거의 완벽하게 맞춰 놓지 않았나 싶습니다.
새로운 DB를 크롤링하여 다른 방법으로 데이터를 가공, 추출하면 성능이 나아질 것으로 예상했습니다.
하지만 딥러닝 프로젝트 특성상 많은 시간이 필요해서 실천에 옮기지는 못했습니다.
연쇄적으로 특성 추출하는 부분에서 사용할 NAVER OCR API도 사용하지 못하게 되었습니다.


# Genetic Algorithm 설명

- Presentation : Integer & Permutate encoding
- Chromosome : 길이가 5인 순열, 각 요소는 챔피언의 고유 아이디.
- Fitness : 현재 챔피언이 참여한 게임의 승률
- Operators
    - Selection
        - 현재의 population에서 부모 chromosomes를 선택하는 방법.
        - Roulette Wheel 기법을 사용.
            - Chromosome의 fitness에 따라 확률적으로 우수한 chromosome을 선택.
    - Crossover
        - 두 개의 chromsome을 결합하는 방법.
        - 우수한 chromosome을 유지하는 방법.
        - PMX 기법을 사용.
            - 순열 인코딩의 chromosom에 적합.
    - Mutation
        - 현재의 chromsome에서 일정 확률로 값을 변경하는 방법.
        - 탐색 공간을 넓히기 위한 방법.
        - Flip 기법을 사용.
            - 현재 chromosome에 존재하는 챔피언 한 개를 다른 챔피언으로 변경함.
    - Replacement
        - 현재의 population의 일부 chromosome을 새로운 chromosome으로 변경하는 방법.
        - Population의 평균 fitness를 향상시키기 위한 방법.
        - Worst 또는 Best chromosome을 대체하는 기법을 사용.
            - 80% 의 확률로 Worst 를 대체.
            - 20% 의 확률로 Best 를 대체.
            - Best를 대체하는 이유는, 이른 수렴을 방지하기 위함.


# Kube Flow (?)
![image](https://user-images.githubusercontent.com/12825679/74513731-98ee0300-4f4e-11ea-9120-627a8d3fa573.png)

NCP의 Kubernetes 서비스를 활용하였습니다. nginx-ingress 를 기반으로 구현하였습니다.
이후 GA기반 백엔드와 PyTorch기반 백엔드를 마이크로 서비스로 구성하고 모든 서비스의 가용성을 위해 replica 3를 두었습니다.
이후 cronjob을 통해 크롤링 및 새로운 학습을 trigger하고, 같은 pod 내에 엮여있는 model server (Gin, Flask) 들에게 volume share로 모델을 전달하여 배포시간을 최소화합니다.

여기까지가 구상하고 준비한 부분인데, 현재로는 아래와 같이 두 앱만 구성되어있습니다. (argocd 폴더에서 yaml 확인 가능합니다)
![image](https://user-images.githubusercontent.com/12825679/74514019-26c9ee00-4f4f-11ea-9a13-834b4f5fcfd8.png)
위의 두 앱이 구성되어잇고 각각 아래와 같이 구성되어 있습니다.
### deeplol (web)
![image](https://user-images.githubusercontent.com/12825679/74514057-36e1cd80-4f4f-11ea-8cc4-2233dadd0807.png)
### ga (유전알고리즘)
![image](https://user-images.githubusercontent.com/12825679/74514095-45c88000-4f4f-11ea-8ce7-2cb35660dde5.png)


### 프로젝트 CD
각 프로젝트를 dockerize 하였습니다. 그리고 모든 backend 상호관계 객체들을 환경변수에 의존하여 resource 연결하게함으로서 컨테이너화를 하였습니다. 

ArgoCD 를 사용해 github repository 와 integeration 하였고 gui로 관리하며 on-the-fly 수정편집배포가 가능하도록 하였습니다.


# Why Go?
요즘 개발자들에게 인기라 불리우는 고랭은 속도도 빠르지만 특별히 배포에 특화된 언어이기도하빈다. 바이너리로 떨어지는 빌드 아웃풋은 도커컨테이너에 담아 배포하기 매우 편리하며 또한 alpine보다 작은 scratch 에 담아 배포할 수 도 있습니다. 

유전 알고리즘 등에서도 빛을 발할 수 있었던 것은 세대별로 나뉘어지는 등에 작업에서 go routine을 사용해 작성하기쉽고 빠른 멀티스레딩 알고리즘을 작성할 수 있었기 때문입니다.


# 프로젝트 운영 방식

1시간마다 sprint를 진행하였습니다. 이렇게 한 이유는 기술적인 목표는 높을지 모르나 현실적인 한계에 부딪혀 시간낭비하지 않기 위함이었습니다.

**완벽보단 완성** 이라는 명목 하에 아래와같이 각 시각별 진행사항 등을 기록하였습니다.
![image](https://user-images.githubusercontent.com/12825679/74514812-b1f7b380-4f50-11ea-824a-c97606e02b45.png)

*5시반쯤에 죽었습니다*



# 마치며...

저희는 해커톤용 프로젝트라기보단 실제 서비스를 하고 싶었습니다. 돈을 벌려는 목적보다는 실제로 인공지능 서비스가 실 생활에 다가오고 생활을 바꾸었으면 좋겠다는 생각에서 많은 사람들의 삶에 가까이 있는 게임 롤에 인공지능서비스를 접하려고 했습니다.

해커톤의 시간적 제한 특성상 큰 결과물을 내지못해 아쉬운 마음이 큽니다. 학습함에 있어서도 롤 같은 경우 매우 밸런스에 예민한 게임이다 보니 이미 이정도의 딥러닝 시스템들은 밸런스를 맞추기위해 구성되어 있을거라 생각합니다.

부족한 실력으로 도전할 수 있는 기회를 주셔서 감사합니다. 다음 기회가 또 있다면 더욱이 발전한 모습으로 도전하고 싶습니다. 감사합니다.





